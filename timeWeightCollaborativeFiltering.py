# -*- coding: utf-8 -*-
"""assignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CTBxK_PAnq_uksQknaMqcD8Lzwv9kkTI
"""

pip install fastFM

import os
import json
import gzip
import pandas as pd
from urllib.request import urlopen

import random
import numpy as np
from collections import defaultdict
import seaborn as sns
import sklearn
from sklearn import linear_model
import dateutil
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import scipy
from fastFM import als
from sklearn.metrics import mean_squared_error
import math
from gensim.models import Word2Vec
from nltk.stem.porter import *
from sklearn import linear_model
from sklearn.manifold import TSNE
import string

!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFilesSmall/Industrial_and_Scientific_5.json.gz

### load the meta data

data = []
with gzip.open('Industrial_and_Scientific_5.json.gz') as f:
    for l in f:
        data.append(json.loads(l.strip()))

# total length of list, this number equals total number of products
print(len(data))

# first row of the list
print(data[0])

# convert list into pandas dataframe

df = pd.DataFrame.from_dict(data)

print(len(df))

# Fill None values with empty strings
df3 = df.fillna('')

# # Filter rows where reviewText contains 'getTime'
# df4 = df3[df3.reviewText.str.contains('getTime')] # unformatted rows

# # Filter out rows where reviewText contains 'getTime'
# df5 = df3[~df3.reviewText.str.contains('getTime')] # formatted rows

# print(len(df4))
# print(len(df5))

# EXPLORATORY ANALYSIS
print(data[0])
print('entries: ' + str(len(data)))

# set of all users
allUsers = set()

# set of all items
allItems = set()

# set of all review texts
reviews = []

reviewData = []
for d in data:
  if 'reviewText' in d:
    reviewData.append(d) # getting rid of reviews without text
    allUsers.add(d['reviewerID'])
    allItems.add(d['asin'])
    reviews.append(d['reviewText'])
print('users: ' + str(len(allUsers)))
print('items: ' + str(len(allItems)))
print('cleaned data: ' + str(len(reviewData)))

# Convert cleaned data to a DataFrame
reviewData_df = pd.DataFrame(reviewData)

# Create a histogram of the 'quality' column
sns.histplot(reviewData_df['overall'])

reviewData_df.head()

# Extract the review dates
review_dates = pd.to_datetime(reviewData_df['reviewTime'])

# Find the start and end of the time period
start_date = review_dates.min()
end_date = review_dates.max()

print('The dataset covers the time period from ' + start_date.strftime('%B %d, %Y') + ' to ' + end_date.strftime('%B %d, %Y'))

"""Sliding window"""

ratingsTime = []

for d in reviewData:
    t = dateutil.parser.parse(d['reviewTime'])
    ratingsTime.append((t,d['overall'], d['unixReviewTime']))
    if len(ratingsTime) >= 50000:
        break

# sort observations by time
ratingsTime.sort()
len(ratingsTime)

# Keep track of a window (wSize) of ratings and timestamps (the raw time is just for printing the plot)
wSize = 1000
x = [r[0] for r in ratingsTime] # as raw times
y = [r[1] for r in ratingsTime] # ratings
xu = [r[2] for r in ratingsTime] # as unix times

# Use a dynamic-programming approach to build the sliding window
xSum = sum(xu[:wSize])
ySum = sum(y[:wSize])
sliding = []

for i in range(wSize,len(x)-1):
    xSum += xu[i] - xu[i-wSize]
    ySum += y[i] - y[i-wSize]
    sliding.append((xSum*1.0/wSize,ySum*1.0/wSize))

#X and Y coordinates for plotting
X = [a[0] for a in sliding]
Y = [a[1] for a in sliding]

plt.plot(X[::1000],Y[::1000], label="5000 rating window", color='k')
plt.xticks([X[600], X[-350]], [x[wSize+600].strftime("%d/%m/%Y"), x[-350].strftime("%d/%m/%Y")])
plt.xlim(X[0], X[-1])
plt.ylabel("Rating")
plt.xlabel("Date")
plt.legend(loc="best",fontsize=8)
plt.title("Ratings over time (sliding windows)")
plt.show()

"""Word Cloud"""

from wordcloud import WordCloud, STOPWORDS

# Define the text for the word cloud
text = ' '.join([d['reviewText'] for d in reviewData])

# Generate the word cloud
wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white').generate(text)

# Plot the word cloud
plt.figure(figsize=(8, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.tight_layout(pad=0)
plt.show()

# Define the size of each set
train_size = 0.5 # 50% of the data for training
test_size = 0.5 # 50% of the data for testing

# Calculate the indices for each set
train_end = int(len(reviewData) * train_size)

# Split the data
dataTrain = reviewData[:train_end]
dataTest = reviewData[train_end:]

# Print the size of each set
print(len(dataTrain), len(dataTest))

def feature(d):
    feat = [1] # Constant feature
    feat.append(len(d['reviewText'])) # Length of review
    return feat

X = [feature(d) for d in dataTrain]
y = [d['overall'] for d in dataTrain]

#Fit the model and extract the coefficients

model = sklearn.linear_model.LinearRegression(fit_intercept=False)
model.fit(X, y)
theta = model.coef_
theta

Xtest = [feature(d) for d in dataTest]
y_pred = model.predict(Xtest)

sse = sum([x**2 for x in (y - y_pred)])
mse = sse / len(y)
mse

"""Predicting mean baseline"""

ratingMean = sum(d['overall'] for d in dataTrain) / len(dataTrain)

y_pred = [ratingMean for d in dataTest]
y = [d['overall'] for d in dataTest]

# Calculate the MSE
mse = mean_squared_error(y, y_pred)

print(mse)

"""FISM"""

userIDs = {}
itemIDs = {}
interactions = []
interactionsPerUser = defaultdict(list)
for d in reviewData:
    u = d['reviewerID']
    i = d['asin']
    t = d['reviewTime']
    r = d['overall']
    dt = dateutil.parser.parse(t)
    t = int(dt.timestamp())
    if not u in userIDs: userIDs[u] = len(userIDs)
    if not i in itemIDs: itemIDs[i] = len(itemIDs)
    interactions.append((t,u,i,r))
    interactionsPerUser[u].append((t,i,r))

# Interaction with timestamp
interactions[0]

len(interactions)

# Sort interactions by time (including interaction sequences for each user). Useful when building data structures that include adjacent pairs of interactions (but consider whether this is desirable if making train/test splits!).
interactions = [x for x in interactions if x[3] is not None]
interactions.sort()

nItems = len(itemIDs)
nUsers = len(userIDs)

fismInter = random.sample(interactions,75000)

#Factorization machine design matrix. Note that we have two sets of features (the user history, and the target item). Both are of dimension nItems.

X = scipy.sparse.lil_matrix((len(fismInter), 2*nItems))

itemsPerUser = defaultdict(set)
for _,u,i,_ in interactions:
    itemsPerUser[u].add(i)

for n in range(len(fismInter)):
    _,u,i,r = fismInter[n]
    item = itemIDs[i]
    history = itemsPerUser[u]
    for j in history:
        if i == j: continue # Exclude the target item from the history
        X[n,itemIDs[j]] = 1.0 / (len(history) - 1) # One-hot encoding, normalized by history length
    X[n,nItems + item] = 1

y = np.array([r for _,_,_,r in fismInter])

#Fairly slow and memory-hungry (every row contains a copy of a user's history). Could possibly be implemented faster in Tensorflow.

fm = als.FMRegression(n_iter=1000, init_stdev=0.1, rank=5, l2_reg_w=0.1, l2_reg_V=0.5)

X_train,y_train = X[:67500],y[:67500]
X_test,y_test = X[67500:],y[67500:]

fm.fit(X_train, y_train)

y_pred = fm.predict(X_test)

def MSE(predictions, labels):
   differences = [(x-y)**2 for x,y in zip(predictions,labels)]
   return sum(differences) / len(differences)

MSE(y_pred, y_test)

"""Autoregression"""

events = {}

for d in dataTrain:
  itemID = d['asin']
  timeString = d['reviewTime']
  # Convert the review date to a Unix timestamp
  timeUnix = d['unixReviewTime']
  # Store the  ID and the Unix timestamp in the events dictionary
  events[itemID] = [timeUnix, timeString]

# Find the earliest event (so that we can sort events from the first to the last hour)
earliest = None
for event in events:
    if earliest == None or events[event][0] < earliest[0]:
        earliest = events[event]

earliestTime = earliest[0]

# Count events by hour
hourly = defaultdict(int)

for event in events:
    t = events[event][0]
    hour = int(t - earliestTime) // (60*60)
    hourly[hour] += 1

def feature(hour):
    previousHours = []
    # Features for last 5 hours, one day ago, one week ago, and one year ago
    for i in [1,2,3,4,5,24,24*7,24*7*365]:
        previousHour = hour - i
        previousHourExists = previousHour in hourly
        if previousHourExists:
            previousHours += [hourly[previousHour]]
        else:
            previousHours += [0]
    return previousHours

X = [feature(x) for x in hourly]
y = [hourly[x] for x in hourly]

model = sklearn.linear_model.LinearRegression(fit_intercept=False)
model.fit(X, y)
theta = model.coef_

theta
# The observation from a year ago is the most predictive, followed by the one from the previous week

y_pred = model.predict(X)

MSE(y, y_pred)

"""Similarity model adapted to time-weight collaborative filtering"""

def Jaccard(s1, s2):
    numer = len(s1.intersection(s2))
    denom = len(s1.union(s2))
    if denom == 0:
        return 0
    return numer / denom

def CosineSet(s1, s2):
    # Not a proper implementation, operates on sets so correct for interactions only
    numer = len(s1.intersection(s2))
    denom = math.sqrt(len(s1)) * math.sqrt(len(s2))
    if denom == 0:
        return 0
    return numer / denom

usersPerItem = defaultdict(set) # Maps an item to the users who rated it
itemsPerUser = defaultdict(set) # Maps a user to the items that they rated
itemNames = {}
ratingDict = {} # To retrieve a rating for a specific user/item pair

for d in dataTrain:
    user,item = d['reviewerID'], d['asin']
    usersPerItem[item].add(user)
    itemsPerUser[user].add(item)
    ratingDict[(user,item)] = int(d['overall'])

userAverages = {}
itemAverages = {}

for u in itemsPerUser:
    rs = [ratingDict[(u,i)] for i in itemsPerUser[u]]
    userAverages[u] = sum(rs) / len(rs)

for i in usersPerItem:
    rs = [ratingDict[(u,i)] for u in usersPerItem[i]]
    itemAverages[i] = sum(rs) / len(rs)

#Use our similarity functions to estimate ratings. Start by building a few utility data structures.

reviewsPerUser = defaultdict(list)
reviewsPerItem = defaultdict(list)

for d in dataTrain:
    user,item = d['reviewerID'], d['asin']
    reviewsPerUser[user].append(d)
    reviewsPerItem[item].append(d)

ratingMean = sum(d['overall'] for d in dataTrain) / len(dataTrain)

ratingMean

#Rating prediction heuristic (several alternatives from Chapter 4 could be used)

def predictRating(user,item,timestamp):
    ratings = []
    similarities = []
    timesList = []
    for d in reviewsPerUser[user]:
        i2 = d['asin']
        if i2 == item: continue
        ratings.append(d['overall'] - itemAverages[i2])
        # Calculate the Jaccard similarity with the time-based weighting factor
        similarities.append(CosineSet(usersPerItem[item],usersPerItem[i2]))
        date = d['unixReviewTime']
        timesList.append(math.exp(-5*timestamp))
    if (sum(similarities) > 0):
        weightedRatings = [(x*y*z) for x,y,z in zip(ratings,similarities,timesList)]
        temp = [(y*z) for y,z in zip(similarities,timesList)]
        return itemAverages[item] + sum(weightedRatings) / (sum(temp)+1)
        #return itemAverages[item] + sum(weightedRatings) / sum(similarities)*sum(timesList)
    else:
        if item in itemAverages:
            return itemAverages[item] #returning item avg if seen before
        # User hasn't rated any similar items
        return ratingMean

def MSE(predictions, labels):
    differences = [(x-y)**2 for x,y in zip(predictions,labels)]
    return sum(differences) / len(differences)

#Compared to a trivial predictor which always predicts the mean

alwaysPredictMean = [ratingMean for d in dataTest]

#Get predictions for all instances (fairly slow!)

simPredictions = [predictRating(d['reviewerID'], d['asin'], d['unixReviewTime']) for d in dataTest]

labels = [d['overall'] for d in dataTest]

MSE(alwaysPredictMean, labels)

#MSE(simPredictions, labels)
print(f"The Mean Squared Error of the time weight collaborative filtering model is {MSE(simPredictions, labels)}")

# Generate random ratings
random_ratings = np.random.uniform(low=1, high=5, size=(len(reviewData),))

# Calculate the MSE of the random ratings
mse = mean_squared_error(random_ratings, [d['overall'] for d in reviewData])

print(f"The Mean Squared Error of the dummy random baseline model is {mse}")

"""Word"""

wordCount = defaultdict(int)
for d in reviewData:
    for w in d['reviewText'].split():
        wordCount[w] += 1

len(wordCount) # unique words

# Ignore capitalization and remove punctuation

wordCount = defaultdict(int)
punctuation = set(string.punctuation)
for d in reviewData:
    r = ''.join([c for c in d['reviewText'].lower() if not c in punctuation])
    for w in r.split():
        wordCount[w] += 1

len(wordCount)

#With stemming

wordCount = defaultdict(int)
punctuation = set(string.punctuation)
stemmer = PorterStemmer()
for d in reviewData:
  r = ''.join([c for c in d['reviewText'].lower() if not c in punctuation])
  for w in r.split():
    w = stemmer.stem(w)
    wordCount[w] += 1

len(wordCount)

#Just build our feature vector by taking the most popular words (lowercase, punctuation removed, but no stemming)

wordCount = defaultdict(int)
punctuation = set(string.punctuation)
for d in reviewData:
  r = ''.join([c for c in d['reviewText'].lower() if not c in punctuation])
  for w in r.split():
    wordCount[w] += 1

counts = [(wordCount[w], w) for w in wordCount]
counts.sort()
counts.reverse()

words = [x[1] for x in counts[:1000]]

"""Jaccard"""

reviewsPerUser = defaultdict(list)
reviewsPerItem = defaultdict(list)

for d in dataTrain:
    user,item = d['reviewerID'], d['asin']
    reviewsPerUser[user].append(d)
    reviewsPerItem[item].append(d)

ratingMean = sum(d['overall'] for d in dataTrain) / len(dataTrain)

def predictRating(user,item):
    ratings = []
    similarities = []
    for d in reviewsPerUser[user]:
        i2 = d['asin']
        if i2 == item: continue
        ratings.append(d['overall'] - itemAverages[i2])
        similarities.append(Jaccard(usersPerItem[item],usersPerItem[i2]))
    if (sum(similarities) > 0):
        weightedRatings = [(x*y) for x,y in zip(ratings,similarities)]
        return itemAverages[item] + sum(weightedRatings) / sum(similarities)
    else:
        # User hasn't rated any similar items
        return ratingMean

simPredictions = [predictRating(d['reviewerID'], d['asin']) for d in dataTest]

labels = [d['overall'] for d in dataTest]

MSE(simPredictions, labels)